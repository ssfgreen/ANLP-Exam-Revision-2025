# **PART 1 — SHORT ANSWER QUESTIONS**

### **1. Greedy vs. Beam Search (3 marks)**

You are given the following model output probabilities at each time step for a vocabulary {A, B, C}:

| Step | P(A) | P(B) | P(C) |
| ---- | ---- | ---- | ---- |
| t=1  | 0.4  | 0.5  | 0.1  |
| t=2  | 0.2  | 0.3  | 0.5  |

**(a)** What sequence does **greedy decoding** produce?  
**(b)** For **beam size = 2**, list the two active hypotheses after step 1 and after step 2.  
**(c)** Which sequence does beam search output?

---

### **2. Sampling Temperature (2 marks)**

Your model outputs probabilities:

P(“cat”) = 0.7, P(“dog”) = 0.2, P(“car”) = 0.1.

**(a)** Describe qualitatively how the distribution changes when you increase temperature T > 1.  
**(b)** Which temperature setting (low, medium, high) would most reduce repetition?

---

### **3. Top-k Sampling (3 marks)**

Given distribution:

{“run”: 0.45, “walk”: 0.25, “sleep”: 0.10, “swim”: 0.09, “eat”: 0.08, “fall”: 0.03}.

**(a)** For **k = 3**, list the renormalised probabilities.  
**(b)** Briefly describe a failure mode of top-k sampling.  
**(c)** How does top-p differ conceptually from top-k?

---

### **4. Exposure Bias (2 marks)**

Explain what exposure bias is in **auto-regressive decoding**, and briefly state why it arises from **teacher forcing** during training.

---

### **5. Decoding Efficiency (3 marks)**

LLMs typically use beam search or sampling, but not exhaustive search.

**(a)** Explain why exhaustive search is infeasible.  
**(b)** Give one task where **greedy decoding** usually works well.  
**(c)** Give one task where greedy decoding usually performs poorly and explain why.

---

### **6. Nucleus (top-p) Sampling (3 marks)**

You are given sorted probabilities:

0.35, 0.25, 0.15, 0.10, 0.07, 0.05, 0.03.

**(a)** If p = 0.80, which tokens enter the nucleus?  
**(b)** What problem does top-p solve that top-k does not?  
**(c)** When might top-p behave similarly to greedy decoding?

---

# **PART 2 — EXTENDED QUESTIONS**

### **7. Comparing Decoding Strategies (12 marks)**

A researcher is generating product descriptions using a fine-tuned decoder-only transformer. They try four decoding methods: greedy, beam search (k=5), top-k sampling (k=50), and top-p sampling (p=0.9). They observe:

- Greedy → repetitive, generic text
- Beam → grammatical but overly conservative
- Top-k → creative but sometimes incoherent
- Top-p → best overall, but occasionally contradictory

**(a)** Explain _why_ each decoding strategy produces these characteristic behaviours. (6 marks)  
**(b)** For each method, propose one modification or hyperparameter change to mitigate its weaknesses. (4 marks)  
**(c)** The researcher suggests combining top-k + top-p. Briefly evaluate whether this is useful. (2 marks)

---

### **8. Beam Search in Sequence Generation (10 marks)**

Suppose you have a machine translation model generating English from German.

At each time step, the model outputs the following top-3 next-word probabilities:

- t=1: {the: 0.55, a: 0.25, it: 0.20}
- t=2:
  - after “the”: {cat: 0.40, dog: 0.30, man: 0.30}
  - after “a”: {cat: 0.15, dog: 0.50, man: 0.35}

Assume beam size = 2 and ignore EOS for simplicity.

**(a)** Walk through the beam search process and list the complete set of candidate expansions at t=2. (4 marks)  
**(b)** Identify the final beam. (2 marks)  
**(c)** Explain **two structural limitations** of beam search for neural MT, and one reason beam size is not increased indefinitely. (4 marks)

---

### **9. Human Preference vs. Model Likelihood (10 marks)**

An encoder-decoder NMT system produces two candidate translations:

- **Candidate A**: highest model probability
- **Candidate B**: lower model probability but preferred by human annotators

**(a)** Provide two reasons why **maximum likelihood decoding** (e.g., greedy/beam) may produce worse human-preferred outputs. (4 marks)  
**(b)** Explain how **sampling-based decoding** addresses these issues. (3 marks)  
**(c)** Discuss a scenario where sampling still fails relative to humans. (3 marks)

---

### **10. Analysis of a Faulty Decoding System (10 marks)**

A deployed chatbot frequently produces:

- Long loops (“As an AI, I… As an AI, I…”)
- Contradictions within the same answer
- Sudden topic drift
- Extremely deterministic phrasing despite tuning temperature

You inspect the system and discover:

- Temperature is scaled _before_ softmax instead of _after_.
- Top-p threshold is fixed at 0.5.
- No repetition penalty; no anti-determinism adjustments.
- Training used teacher forcing without scheduled sampling.

**(a)** Explain how each implementation detail contributes to one of the observed problems. (6 marks)  
**(b)** Propose three fixes that would improve generation quality, explaining their effect. (4 marks)

---

# ✅ **Next Section?**

If this format works for you, tell me which section to generate next:

**Models | Other Formulas | Probability Estimation & Learning | Algorithms | Linguistic Concepts | Tasks | Resources | Evaluation | Ethics | Multilingual NLP**

I’ll proceed with the next message in the same style.
