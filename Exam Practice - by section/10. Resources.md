# **Part A — Short Answer Questions (1–3 marks each)**

### **1. (2 marks)**

Give two examples of **linguistic resources** commonly used in NLP.  
For each, state **one advantage** and **one disadvantage**.

---

### **2. (2 marks)**

WordNet is often used in tasks like WSD and semantic similarity.  
Explain **one specific limitation** of WordNet that might reduce performance on modern NLP tasks.

---

### **3. (2 marks)**

CommonCrawl is widely used to train LLMs.  
Give **one reason it is attractive** and **one reason it introduces risks**.

---

### **4. (1 mark)**

What is the difference between a **raw corpus** and an **annotated corpus**?  
Give one example of each.

---

### **5. (3 marks)**

A researcher wants to train a sentiment classifier for Swahili using data scraped from social media.  
List **three challenges** they may face related to resources.

---

### **6. (2 marks)**

Why is it often **legally problematic** to train models on scraped web data?  
Give one legal issue and one ethical issue.

---

### **7. (2 marks)**

Explain the concept of **domain mismatch** when using pretraining corpora.  
Give one example relevant to NLP tasks.

---

### **8. (3 marks)**

For each of the following, give an NLP task where the resource is useful, and briefly state **why**:

a) **Parallel corpora**  
b) **Treebanks**  
c) **Pretrained multilingual embeddings**

---

### **9. (2 marks)**

What is the main difference between **supervised** and **weakly supervised** resources?  
Give an example of each.

---

### **10. (2 marks)**

Why do many NLP datasets include a **license file**, and what might go wrong if a researcher ignores it?

---

---

# **Part B — Extended Questions (10–13 marks total)**

_These mirror the style of the extended questions in past ANLP exams (∼10–12 marks each)._

---

## **11. Extended Question: Building a Resource for a Low-Resource Language (12 marks)**

You are hired to help develop a part-of-speech tagging model for a low-resource language, **Luma**, which has no existing annotated corpora.

### **(a) (3 marks)**

Describe **three possible sources of data** you could use to begin building a POS annotation resource for Luma.  
The sources should differ in how they are obtained.

---

### **(b) (3 marks)**

Explain two types of **annotation guidelines** you would need to create for POS tagging.  
Why are they essential for consistent annotation?

---

### **(c) (3 marks)**

Discuss **two ways** the creation of this dataset could introduce **algorithmic bias**, even if the annotation is correct.

---

### **(d) (3 marks)**

Suppose you also obtain a **parallel corpus** between Luma and English.  
Explain how you could use this resource to improve POS tagging performance without requiring full annotation in Luma.

---

---

## **12. Extended Question: Ethical & Practical Constraints in Dataset Construction (13 marks)**

You are preparing a dataset of mental-health forum posts to train an NLP system that detects early signs of depression.

### **(a) (4 marks)**

Identify and explain **two ethical considerations** in collecting the data.  
For each, propose a mitigation strategy.

---

### **(b) (3 marks)**

Your team proposes using a dataset originally collected for **customer support chatbots** as additional pretraining data.  
Explain one **advantage** and **two specific risks** of this approach.

---

### **(c) (3 marks)**

Explain how **annotation quality** might degrade if annotators are not domain experts.  
Give one concrete example of a likely annotation error.

---

### **(d) (3 marks)**

You want to release the dataset publicly.  
Discuss two things you must check before release, one **legal** and one **ethical**, and explain the consequences of failing to do so.
