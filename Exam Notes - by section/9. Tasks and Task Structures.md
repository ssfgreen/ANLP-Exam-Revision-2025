
# **1. Tokenization**

**What it is:**

- Splitting raw text into **tokens** (words, subwords, punctuation).
- Defines the _basic units_ of all downstream NLP models.

**Examples:**

- “don’t” → {“don”, “’”, “t”} (char-based)
- BPE: “unhappiness” → “un”, “happi”, “ness”

**Ambiguity / Difficulty:**

- **Multi-word expressions:** “New York”, “hot dog”.
- **Agglutinative languages:** very long words (e.g., Turkish).
- **No whitespace languages:** Chinese, Japanese → segmentation is non-trivial.

**Algorithms / Methods:**

- Rule-based tokenizers, whitespace tokenizers.
- **Subword models**: BPE, WordPiece, SentencePiece.

**Evaluation:**

- Intrinsically rare; typically evaluated indirectly via downstream task performance.

**Task Structure:**

- **Preprocessing step**, not a prediction task.

---

# **2. Language Modelling (LM)**

**What it is:**

- Predicting the **next token** given previous context:  
   **P(wₜ | w₁ … wₜ₋₁)**.

**Examples:**

- Predict the next word: “The cat sat on the \_\_\_”.

**Ambiguity / Difficulty:**

- **Long-distance dependencies:** LM must capture grammar agreement, discourse cues.
- **Sparsity:** Rare n-grams severely weaken count-based models.
- **Unbounded vocabulary / OOV:** mitigated by subword tokenization.

**Algorithms / Methods:**

- **N-gram models (+ smoothing).**
- **Neural LMs:** RNN, LSTM, GRU.
- **Transformers:** GPT-style causal LMs.

**Evaluation:**

- **Perplexity** (exp of average negative log-likelihood).
- Intrinsic, task-specific.

**Task Structure:**

- **Sequence prediction** (autoregressive).
- **Generative model.**

---

# **3. Text Categorization (Sentiment, Topic Classification, etc.)**

**What it is:**

- Assigning one label (or set of labels) to a text span.
- Examples: **Sentiment** (positive/negative), **Spam detection**, **Topic** (sports, politics).

**Ambiguity / Difficulty:**

- **Sarcasm / Irony:** “Great job…” (negative sentiment).
- **Domain shift:** model trained on movie reviews performs poorly on finance tweets.
- **Multi-label vs single-label:** deciding task structure affects modelling.

**Algorithms / Methods:**

- Logistic regression, linear SVMs.
- Bag-of-words, TF-IDF, embeddings → classifiers.
- Fine-tuned transformers (BERT, RoBERTa).

**Evaluation:**

- **Accuracy**, **Precision/Recall/F1**, **Confusion matrix**.
- Macro-F1 for imbalanced classes.

**Task Structure:**

- **Classification** (single label) or **multi-label classification**.

---

# **4. Word Sense Disambiguation (WSD)**

**What it is:**

- Assigning the correct **sense** of a polysemous word in context.
- Example: “bank” = _riverbank_ vs _financial institution_.

**Ambiguity / Difficulty:**

- **Lexical ambiguity** is large and context-dependent.
- Senses in resources (WordNet) may not align with real usage.
- Many senses are extremely rare → sparse data problem.

**Algorithms / Methods:**

- Knowledge-based: Lesk algorithm (overlap).
- Supervised classifiers using context windows.
- Transformer contextual embeddings (state-of-the-art).

**Evaluation:**

- Sense-level **accuracy** vs a gold dataset (e.g., SemCor).

**Task Structure:**

- **Classification** over senses of a single target word.

---

# **5. Sequence-to-Sequence Tasks**

_(Machine translation, summarization, data-to-text, style transfer)_

**What they are:**

- Input sequence → **output sequence**, often of different length.
- Examples:
  - **Machine Translation:** “Je suis fatigué” → “I am tired.”
  - **Summarization:** long article → short abstract.

**Ambiguity / Difficulty:**

- **Multiple correct outputs** → evaluation is hard.
- **Alignment** between source and target tokens is implicit and complex.
- **Long-range reasoning** required (especially summarization).
- **Hallucinations** in generative models.

**Algorithms / Methods:**

- Seq2Seq RNNs w/ attention (Bahdanau, Luong).
- Transformer encoder–decoder (e.g., T5, BART).
- Causal LMs with prompt-based decoding.

**Evaluation:**

- **BLEU**, **ROUGE**, **METEOR** (n-gram overlap).
- Increasingly: human evaluation, BERTScore.

**Task Structure:**

- **Sequence-to-sequence generation**, conditional generation.

---

# **6. Open-Ended Conversational AI**

**What it is:**

- Systems that generate **contextually appropriate, multi-turn dialogue**.
- Not a closed classification task—output space is unbounded.

**Examples:**

- Chatbots, customer support assistants, tutoring systems.

**Ambiguity / Difficulty:**

- **Ambiguous intent**: user messages underspecified.
- **Long context tracking**: maintaining state across turns.
- **Safety & grounding**: misinformation, hallucinations, harmful responses.
- **Evaluation** inherently subjective.

**Algorithms / Methods:**

- Large Language Models (GPT-style).
- Retrieval-augmented generation (RAG).
- Reinforcement learning (e.g., RLHF, RLVR).

**Evaluation:**

- Hard! Typically:
  - **Human judgments** (quality, relevance, safety).
  - **Automated metrics** (BLEU, embedding similarity) but imperfect.
  - **Task-specific** scoring (goal completion in task-oriented agents).

**Task Structure:**

- **Open-ended generation** (not finite-label).
- Often modeled as **sequence-to-sequence** or **autoregressive LM** with memory.

---

# **7. Identifying Task Structures (Meta-Skill)**

You should be able to recognise, for a **newly described task**, which structure it fits:

| Task                            | Structure                              |
| ------------------------------- | -------------------------------------- |
| POS tagging                     | **Sequence labelling**                 |
| Named entity recognition        | **Sequence labelling**                 |
| Spam detection                  | **Classification**                     |
| MT / Summarization              | **Seq2Seq**                            |
| Dialogue generation             | **Open-ended generation**              |
| Question answering (extractive) | **Span prediction**                    |
| Coreference resolution          | **Clustering / structured prediction** |

Key cues:

- **Is the output one label?** → classification.
- **Label per token?** → sequence labelling.
- **Output is a new sequence?** → seq2seq.
- **Output is unconstrained free text?** → generative LM task.

---

# **TLDR — Core Expectations**

- Know **what each task is**, with **examples**, **ambiguities**, **difficulty sources**.
- Know **typical algorithms**: N-grams, logistic regression, transformers, seq2seq.
- Know **evaluation metrics**: accuracy, F1, perplexity, BLEU/ROUGE.
- For **new tasks**, quickly identify if it's **classification / seq-labelling / seq2seq / open-gen**.
