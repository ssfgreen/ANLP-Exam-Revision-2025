## **1. Ambiguity (multiple forms)**

**Core idea:** A single surface form can map to multiple interpretations.  
**Why it matters:** NLP systems must resolve ambiguity to correctly parse, classify, translate, or answer questions.

### **Types**

- - **Lexical ambiguity (word sense):**  
    _bank_ = _financial institution_ vs _river edge_.  
    Relevant to: **WSD**, MT, IR.
- **Parts of speech ambiguity:**  
   _flies_ = noun (“insects”) or verb (“he flies”).  
   Relevant to: **tagging**, morphological analyzers.
- Morphological ambiguity:
	- "Untiable" = able to be untied OR not able to be tied?
- **Syntactic (structural) ambiguity:**  
   _I saw an elephant in my pyjamas._  
   (Attachment of PP unclear)
- **Attachment ambiguity:**  
   _I saw the man with the telescope._  
   Relevant to: **parsing**, semantic role labelling.
- **Word-order ambiguity:**  
   _Old men and women._  
   Relevant to: **parsing**, MT.
- **Referential ambiguity**
   _Mary told Jane she should leave._ (“she” unclear)
- **Idiomatic ambiguity:**  
   _kick the bucket_ → literal vs idiomatic.

---

## **2. Agreement**

**Core idea:** Certain grammatical features must match across elements.

### **Types of agreement**

- **Verb–argument agreement:**
  - _She runs_ vs _They run_.
  - Relevant to: **syntactic parsing**, LM scoring.
- **Co-reference agreement:**
  - Pronouns must match antecedent number/gender: _Mary said she…_
  - Relevant to: **coreference resolution**.
- **Language-specific agreement features:**
  - **Case** (German, Russian), **gender** (Spanish), **number**.
  - Relevant to: MT, parsing, morphology modelling.

### **Long-distance dependencies**

- Agreement can span clauses:
  - _The bouquet of roses **was** lovely._
  - Relevant to: assessing **context windows**, identifying **limitations of n-gram models**.

---

## **3. Word Types vs Tokens & Tokenization**

- **Tokens:** individual surface occurrences in text.
  - _“the cat sat”_ → 3 tokens.
- **Types:** unique word forms in a corpus.
  - In that sentence, 3 types (all unique).

**Tokenization issues:**

- Hyphens, contractions (_don’t → do + n’t_), multiword expressions.
- Relevant to: **BPE**, vocabulary construction, embeddings.

---

## **4. Stems, Affixes, Root, Lemma**

- **Root:** irreducible lexical core (_scrib-_).
- **Stem:** form to which affixes attach (_scrib(e)_).
- **Affixes:** prefixes/suffixes (_un-_, _-ing_).
- **Lemma:** dictionary form (_run_ vs _running_, _ran_).

**Relevant to:** morphological analyzers, MT, IR normalisation.

---

## **5. Inflectional vs Derivational Morphology**

- **Inflectional:** alters grammatical features; **does not change word class**.
  - _walk → walked_ (tense), _cat → cats_ (number).
  - Relevant to: POS tagging, parsing.
- **Derivational:** forms **new lexemes**, often **changes word class**.
  - _happy → happiness_, _teach → teacher_.
  - Relevant to: vocabulary growth, embeddings, MT.

**Case, gender, number marking:**

- Languages vary: Romance (gender), Slavic (case), English (mostly number/tense).

Note: Morphological richness → **data sparsity**, more word forms → harder for n-grams, embeddings, tagging.

---

## **6. Dialects**

- Variation in vocabulary, syntax, spelling, morphology.
- Variety by region, class or culture. typically mutually intelligable.
- Examples: _colour/color_, _you all/y’all_.
- Relevant to: LM robustness, MT, speech-to-text, fairness.

---

## **7. Part-of-Speech (POS)**

- Grammatical categories (noun, verb, adj…).
- Important because POS constrains syntactic structure.
- Ambiguity common: _book_ (noun/verb).
- Relevant to: tagging, parsing, downstream tasks.

---

## **8. Open-class vs Closed-class Words**

- **Open-class:** nouns, verbs, adjectives, adverbs.
  - Semantically rich; new words appear.
  - Important for embeddings, semantics.
- **Closed-class:** determiners, prepositions, pronouns, conjunctions.
  - Rarely grow; grammatical glue.
  - Important for syntax modelling.

---

## **9. Long-Distance Dependencies**

- Dependencies spanning large distances or intervening material.
- Examples:
  - Subject–verb agreement: _The key to the cabinets **is** missing._
  - Wh-movement: _What did John say Mary bought \_\_?_

**Relevance:**

- N-grams fail (limited context).
- Transformers handle via self-attention.

---

## **10. Syntactic Roles**

- **Subject:** agent/performer.
- **Object:** undergoer/patient.
- **Indirect object:** recipient or benefactive.

**Why needed:** semantic role labelling, parsing, MT disambiguation.

---

## **11. Word Senses & Semantic Relations**

- **Synonym:** _big / large_.
- **Hypernym:** _animal_ (hypernym of _dog_).
- **Hyponym:** _poodle_ (hyponym of _dog_).
- **Similarity:** distributional or conceptual closeness.

**Relevance:** WSD, MT, IR, embeddings.

---

## **12. Distributional Hypothesis**

**Definition:**  
_Words that occur in similar contexts tend to have similar meanings._

- Forms basis of **word embeddings**, co-occurrence matrices, skip-gram/CBOW.
- Relevant to: semantics, clustering, similarity tasks.

---

## **13. Static vs Contextualized Embeddings**

### **Static embeddings**

- One vector per word type (e.g., **word2vec**, **GloVe**).
- Cannot capture polysemy (_bank_ has one vector).
- Trained using distributional context.

### **Contextual embeddings**

- One vector per **token** in context (e.g., **ELMo**, **BERT**, **GPT**).
- Capture polysemy, subtle syntactic/semantic relations.
- Generated via **deep language models** during inference.

**Relevance:** nearly all modern NLP (NER, MT, QA, sentiment).

---

# **TLDR**

- Ambiguity drives most NLP difficulty; know types and examples.
- Agreement involves number/gender/case dependencies; can be long-distance.
- Tokens ≠ types; tokenization matters for BPE and embeddings.
- Morphology: roots, lemmas, inflection vs derivation.
- POS, syntactic roles, open/closed classes guide parsing.
- Word senses + semantic relations feed into WSD, MT, IR.
- Distributional hypothesis underpins embeddings.
- Static embeddings = type-level; contextual embeddings = token-level, context-sensitive.